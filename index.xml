<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://jumpynitro.github.io/blog/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jumpynitro.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MPCC: Matching priors and conditional for clustering</title>
      <link>https://jumpynitro.github.io/blog/2022/07/mpcc/</link>
      <pubDate>Thu, 07 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/2022/07/mpcc/</guid>
      <description>Generative adversarial model for clustering. This model is derived from a KL Divergence perspective between inference and generative distributions.</description>
    </item>
    
    <item>
      <title>Generative-inference models: Theory and empirical analysis (Part II)</title>
      <link>https://jumpynitro.github.io/blog/2022/07/gim2/</link>
      <pubDate>Wed, 06 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/2022/07/gim2/</guid>
      <description>Many Generative models have an infertence counter part. In this work we explore how they are formulated. We also studied their representation learning and generative capabilities theoretically and empirically.</description>
    </item>
    
    <item>
      <title>Generative-inference models: Theory and empirical analysis (Part I)</title>
      <link>https://jumpynitro.github.io/blog/2022/07/gim1/</link>
      <pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/2022/07/gim1/</guid>
      <description>Many Generative models have an infertence counter part. In this work we explore how they are formulated. We also studied their representation learning and generative capabilities theoretically and empirically.</description>
    </item>
    
    <item>
      <title>AGP: Amortized Gaussian Process</title>
      <link>https://jumpynitro.github.io/blog/2022/07/agp/</link>
      <pubDate>Mon, 04 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/2022/07/agp/</guid>
      <description>Amortized Gaussian Process is a model that amortizes the computation of a Gaussian Process. With this model we can use autoencoder for time series with variable length and irregular sampling.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://jumpynitro.github.io/blog/research/</link>
      <pubDate>Sun, 03 Jul 2022 15:59:37 -0400</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/research/</guid>
      <description>There is a lot of current work from my thesis that I have not published yet. I currently working with Pablo Huijse, Pavlos Prototopapas and Pablo Estvéz to make this work available as papers. You can have an idea of this work here. The following work is already published.
Publications  Nicolas Astorga, Pablo Huijse, Pavlos Protopapas and Pablo A. Estévez. “MPCC: Matching Priors and Conditionals for clustering”, European Conference on Computer Vision (ECCV), Glasglow, 2020.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://jumpynitro.github.io/blog/categories123/</link>
      <pubDate>Sun, 03 Jul 2022 15:59:37 -0400</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/categories123/</guid>
      <description>fasdfdaafadfadfasdfsd</description>
    </item>
    
    <item>
      <title>Nicolás Astorga</title>
      <link>https://jumpynitro.github.io/blog/about/</link>
      <pubDate>Sun, 03 Jul 2022 15:59:37 -0400</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/about/</guid>
      <description>My ML objective I am an ML researcher that is passionate, really passionate, about machine learning. I want to develop models capable of extracting the most information from all available data sources. At the same time, I want these models can generalize to multiple tasks or target data distributions. In this development process I want to learn the most and help humanity using these autonomous models.
Research interests I think to develop such general models it is necesary to learn various ML subdiscplines: generative models, ML architectures, RL, transfer learning, causal structure learning, etc.</description>
    </item>
    
    <item>
      <title>Working at ALeRCE</title>
      <link>https://jumpynitro.github.io/blog/industry/</link>
      <pubDate>Sun, 03 Jul 2022 15:59:37 -0400</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/industry/</guid>
      <description>Currently, I am working part-time in ALeRCE (Automatic Learning for the Rapid Classification of Events) as machine learning engineer. ALeRCE is a Chilean-led broker that process alert streams of astronomical data. The amount of astronomical data is huge and automonous mecanisms are necesary to detect new interesting astronoimcal objects, since (sadly) we can not put a bunch of astronomers to look images of the sky. Being part of ALeRCE is my closest attempt to engineering, and it has been an entertaining journey.</description>
    </item>
    
    <item>
      <title>LGAd: Lightcurve generative model for anomaly detection</title>
      <link>https://jumpynitro.github.io/blog/2022/07/lgad/</link>
      <pubDate>Sun, 03 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jumpynitro.github.io/blog/2022/07/lgad/</guid>
      <description>We present LGAd, a variational autoencoder for anomaly detection in time series. Anomaly detection is fundamental task in astroinformatics that could allows us to find new astronomical objects not observed in the past.</description>
    </item>
    
  </channel>
</rss>
